{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P_BANTI_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "3a90ba1df6df696511eb0b1e808d81e97f60989a16ef080bf2d615220d4c308f"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksxivohn91AQ"
      },
      "source": [
        "**PROJECT FOR SIMPLE MACHINE LEARNING APPLICATION TO CHECK IRIS_DATASET** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzl5r3c7AD4M"
      },
      "source": [
        "Importing important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaNANB8F-dbp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-8-baf368f80de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2_PzHG4-iPo"
      },
      "source": [
        "Here we are including scikit learn(ML framework) in the dataset module. As calling for load_iris function . To making Machine Learning and statistics for load_iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRI9slul-iex"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-d2fae61619d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miris_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezpk-vjj-iob"
      },
      "source": [
        "Here a BUNCH OBJECT from the iris object which is returned by load_iris .load_iris contains keys and values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MByUTM0X-iwS"
      },
      "source": [
        "print(\"keys of iris_dataset:\\n{}\".format(iris_dataset.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSPRfHRX-i3p"
      },
      "source": [
        " Here the descrption gives us the number of instances and number of attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMk960Dk-i-7"
      },
      "source": [
        "print(iris_dataset['DESCR'][:193] + \"\\n...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyN2E1Da-jFX"
      },
      "source": [
        "The targeted names has been showing below in iris_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRfvJ-rf-jLr"
      },
      "source": [
        "print(\"target names:{}\".format(iris_dataset['target_names']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCVNx-_B-jZD"
      },
      "source": [
        "The feature is needed to be checked for putting the exact one correct place as sepal length (cm) ,sepal width (cm),petal length (cm),petal width (cm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAwAo-hp-jfZ"
      },
      "source": [
        "print(\"features name:\\n{}\".format(iris_dataset['feature_names']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wssOAgzg-jlJ"
      },
      "source": [
        "The type of data in iris_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTixAMUH-jr9"
      },
      "source": [
        "print(\"type of data:{}\".format(type(iris_dataset['data'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtXUKmvJ-jyF"
      },
      "source": [
        "The shape of data in iris_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eye8zSRd-j4j"
      },
      "source": [
        "print(\"shape of data:{}\".format(iris_dataset['data'].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzsZN1R7CQZr"
      },
      "source": [
        "//the number of data is needed to be known form iris_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW6uQNw4CQik"
      },
      "source": [
        "print(\"first ten column of data:\\n{}\".format(iris_dataset['data'][:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBjQ9LzcCQq_"
      },
      "source": [
        "The which type of target is iris_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ouR_cj-kKY"
      },
      "source": [
        "print(\"type of target:{}\".format(type(iris_dataset['target'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwq5YLLM-kTR"
      },
      "source": [
        "The shape of target that how much target is given"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23b_E6ThCqZE"
      },
      "source": [
        "print(\"shape of target:{}\".format(iris_dataset['target'].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVsrXUUXCqoc"
      },
      "source": [
        "Here the species are encoded as integers frm 0 to 2 the integers in iris[target_names] 0 mean sentosa, 1 means versicolor,2 means virginica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GjBs0HaCq1e"
      },
      "source": [
        "print(\"target:\\n{}\".format(iris_dataset['target']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy1_F5nn_f5D"
      },
      "source": [
        "**MEASURING SUCCESS: TRAINING AND TESTING DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpYcQraZAA-U"
      },
      "source": [
        "We want to build a ML model form this data that can predict the species of iris for a new set of measurements. Once the model has been built and trained we would like to test whether it is working or not.\r\n",
        "\r\n",
        "to access the perfommance of model,here the new data will be shown for which we have new labels. This is usually done by splitting the labeled data we have collected into two parts.One of the data is used to build our machine learning model,which is called as the **training data** or **training set**.\r\n",
        "\r\n",
        "In **scikit-learn** data is usually denoted with capital **X**, while labels ara denoted ny a lowercase **y**, this is inspired by the standard formulation **(X)=y** in mathematics, where x is the input to a function and y is\r\n",
        "the output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGSZk_EyEiB-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "iris_dataset[\"data\"], iris_dataset[\"target\"], random_state=0 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj9FlOo6HAuk"
      },
      "source": [
        "To make sure that will get the same output if we run the same function several times, we provide the pseudorandom number generate with a fixed using the **the random_state parameter**.\r\n",
        "\r\n",
        " The output of the train_test_split function is X_train, X_test, y_train, y_test, which are all Numpy arrays. X_train contains 75% of the rows of the dataset, and X_test contains the remaining 25%.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpD239OeJG0v"
      },
      "source": [
        "print(\"X_train shape: {}\".format(X_train.shape))\r\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\r\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\r\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmk71g7mJxOz"
      },
      "source": [
        "**INSPECTING THE DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTkYUWdDJ2K6"
      },
      "source": [
        "Before building any machine learning model it is good to inspecting the data provided,this show correct data inputed and data is good for find abnormalities and preculiarities. maybe some iris data would be predicated as inches in place of centimeters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g-VDyRRLPjS"
      },
      "source": [
        "So here  we gonna apply **k-nearest neighbor algorithm** which implemented as **KNeighborsclassifier** class in the neighbours module.\r\n",
        "Before we can use the model, we need to insitantiate the class into an object . This is when we will set ny parameters of the model.The most important parameter of KNeighboursclassifier is the number of neighbors, which we will set to 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdTTavKWMl5I"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "knn = KNeighborsClassifier(n_neighbors=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpEbtlFsOndP"
      },
      "source": [
        "The knn object encapsulates the algorithm that will be used  to build the model form the training data ,as well the algorithm to make predictions on new data points. To build the model on the training set, we call **fit** method of the knn object, which takes as arguments the Numpy array X_train containing the training data and the Numpy array y_train of the corresponding training labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TqMvGgLPxVe"
      },
      "source": [
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnIm3kc6QAjk"
      },
      "source": [
        "**MAKING PREDICTIONS**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRyaHhWQGh7"
      },
      "source": [
        "We  can make now predictions using the model on new data. imagine we found iris  int the wild\r\n",
        "\r\n",
        "1.  sepal lenght of 5 cm,\r\n",
        "2. a sepal width of 2.9cm\r\n",
        "1.   a petal length of 1 cm\r\n",
        "2.   a petal width of o.2cm\r\n",
        "\r\n",
        "what species of iris would this be? we can calculate it through Numpy array \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26IKl31rRmKQ"
      },
      "source": [
        "X_new =np.array([[5, 2.9, 1, 0.2]])\r\n",
        "print(\"X_new.shape: {}\".format(X_new.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL0fI7GwSE91"
      },
      "source": [
        "To make prediction, we call the **predict** method of the knn object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaP-LAkMSQQU"
      },
      "source": [
        "prediction = knn.predict(X_new)\r\n",
        "\r\n",
        "print(\"prediction:{}\".format(prediction))\r\n",
        "print(\"predicted target name: {}\".format(\r\n",
        "    iris_dataset['target_names'][prediction]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFp98oVYTA9D"
      },
      "source": [
        "**EVALUATING THE MODEL**\r\n",
        "\r\n",
        "This is where the test get evaluated.This data was not used to build the model, but we do know what the correct species is for each row.\r\n",
        "\r\n",
        "therefore, we can make a prediction for each iris in the test data and compare it against its labels. we can measure hoe well thw model wprks by  computing the accuracy which is the fraction of flowers for which the right species was predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCvvz3_IU0Su"
      },
      "source": [
        "y_pred = knn.predict(X_test)\r\n",
        "print(\"test set predictiond:\\n {}\".format(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKlRzqQ8VP3D"
      },
      "source": [
        "print(\"test set score: {}\".format(np.mean(y_pred == y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gACdd7HMV0Mq"
      },
      "source": [
        "                                                                  \r\n",
        "\r\n",
        "# THANK YOU\r\n",
        "\r\n"
      ]
    }
  ]
}